<!-- Source: https://docs.crawl4ai.com/blog/articles/llm-context-revolution/ -->

[Crawl4AI Documentation (v0.7.x)](https://docs.crawl4ai.com/)
  * [ Home ](https://docs.crawl4ai.com/)
  * [ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/)
  * [ Quick Start ](https://docs.crawl4ai.com/core/quickstart/)
  * [ Code Examples ](https://docs.crawl4ai.com/core/examples/)
  * [ Search ](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/)


[ unclecode/crawl4ai ](https://github.com/unclecode/crawl4ai)
Ã—
  * [Home](https://docs.crawl4ai.com/)
  * [Ask AI](https://docs.crawl4ai.com/core/ask-ai/)
  * [Quick Start](https://docs.crawl4ai.com/core/quickstart/)
  * [Code Examples](https://docs.crawl4ai.com/core/examples/)
  * Apps
    * [Demo Apps](https://docs.crawl4ai.com/apps/)
    * [C4A-Script Editor](https://docs.crawl4ai.com/apps/c4a-script/)
    * [LLM Context Builder](https://docs.crawl4ai.com/apps/llmtxt/)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/core/installation/)
    * [Docker Deployment](https://docs.crawl4ai.com/core/docker-deployment/)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/blog/)
    * [Changelog](https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md)
  * Core
    * [Command Line Interface](https://docs.crawl4ai.com/core/cli/)
    * [Simple Crawling](https://docs.crawl4ai.com/core/simple-crawling/)
    * [Deep Crawling](https://docs.crawl4ai.com/core/deep-crawling/)
    * [Adaptive Crawling](https://docs.crawl4ai.com/core/adaptive-crawling/)
    * [URL Seeding](https://docs.crawl4ai.com/core/url-seeding/)
    * [C4A-Script](https://docs.crawl4ai.com/core/c4a-script/)
    * [Crawler Result](https://docs.crawl4ai.com/core/crawler-result/)
    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/core/browser-crawler-config/)
    * [Markdown Generation](https://docs.crawl4ai.com/core/markdown-generation/)
    * [Fit Markdown](https://docs.crawl4ai.com/core/fit-markdown/)
    * [Page Interaction](https://docs.crawl4ai.com/core/page-interaction/)
    * [Content Selection](https://docs.crawl4ai.com/core/content-selection/)
    * [Cache Modes](https://docs.crawl4ai.com/core/cache-modes/)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/core/local-files/)
    * [Link & Media](https://docs.crawl4ai.com/core/link-media/)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/advanced-features/)
    * [Adaptive Strategies](https://docs.crawl4ai.com/advanced/adaptive-strategies/)
    * [Virtual Scroll](https://docs.crawl4ai.com/advanced/virtual-scroll/)
    * [File Downloading](https://docs.crawl4ai.com/advanced/file-downloading/)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/lazy-loading/)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/hooks-auth/)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/proxy-security/)
    * [Undetected Browser](https://docs.crawl4ai.com/advanced/undetected-browser/)
    * [Session Management](https://docs.crawl4ai.com/advanced/session-management/)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/multi-url-crawling/)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/crawl-dispatcher/)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/identity-based-crawling/)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/ssl-certificate/)
    * [Network & Console Capture](https://docs.crawl4ai.com/advanced/network-console-capture/)
    * [PDF Parsing](https://docs.crawl4ai.com/advanced/pdf-parsing/)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/extraction/no-llm-strategies/)
    * [LLM Strategies](https://docs.crawl4ai.com/extraction/llm-strategies/)
    * [Clustering Strategies](https://docs.crawl4ai.com/extraction/clustring-strategies/)
    * [Chunking](https://docs.crawl4ai.com/extraction/chunking/)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/async-webcrawler/)
    * [arun()](https://docs.crawl4ai.com/api/arun/)
    * [arun_many()](https://docs.crawl4ai.com/api/arun_many/)
    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/api/parameters/)
    * [CrawlResult](https://docs.crawl4ai.com/api/crawl-result/)
    * [Strategies](https://docs.crawl4ai.com/api/strategies/)
    * [C4A-Script Reference](https://docs.crawl4ai.com/api/c4a-script-reference/)


* * *
  * [The LLM Context Protocol: Why Your AI Assistant Needs Memory, Reasoning, and Examples](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-llm-context-protocol-why-your-ai-assistant-needs-memory-reasoning-and-examples)
  * [The Problem with Teaching Robots to Code](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-problem-with-teaching-robots-to-code)
  * [Enter the Three-Dimensional Context Protocol](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#enter-the-three-dimensional-context-protocol)
  * [Why This Matters (Especially for Smaller LLMs)](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#why-this-matters-especially-for-smaller-llms)
  * [The Cultural DNA of Your Library](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-cultural-dna-of-your-library)
  * [Beyond Manual Documentation](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#beyond-manual-documentation)
  * [The Protocol, Not the Prescription](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-protocol-not-the-prescription)
  * [Try It Yourself](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#try-it-yourself)
  * [A Final Thought](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#a-final-thought)


# The LLM Context Protocol: Why Your AI Assistant Needs Memory, Reasoning, and Examples
_Published on January 24, 2025 â€¢ 8 min read_
* * *
## The Problem with Teaching Robots to Code
Picture this: You hand someone a dictionary and ask them to write poetry. They know every word, its spelling, its definitionâ€”but do they know how words dance together? How certain combinations evoke emotion while others fall flat? This is exactly what we're doing when we throw API documentation at our AI assistants and expect magic.
I've spent countless hours watching my AI coding assistant struggle with my own library, Crawl4AI. Despite feeding it comprehensive documentation, it would generate code that was _technically_ correct but practically useless. Like a tourist speaking from a phrasebookâ€”grammatically sound, culturally tone-deaf.
## Enter the Three-Dimensional Context Protocol
What if, instead of dumping information, we provided _wisdom_? Not just the "what," but the "how" and "why"? This led me to develop what I call the **LLM Context Protocol** â€”a structured approach that mirrors how humans actually master libraries.
Think of it as HTTP for AI context. Just as HTTP doesn't dictate your website's content but provides a reliable structure for communication, this protocol doesn't prescribe _how_ you write your documentationâ€”it provides a framework for _what_ your AI needs to truly understand your code.
### The Three Pillars of Library Wisdom
#### ðŸ§  **Memory: The Foundation** 
```
# AsyncWebCrawler.arun() - Memory Context

## Signature
async def arun(
    url: str,
    config: CrawlerConfig = None,
    session_id: str = None,
    **kwargs
) -> CrawlResult

## Parameters
- url: Target URL to crawl
- config: Optional configuration object
- session_id: Optional session identifier for caching
...
Copy
```

This is your API referenceâ€”the facts, the parameters, the return types. It's the easiest part to generate and, ironically, the least useful in isolation. It's like memorizing a dictionary without understanding grammar. 
#### ðŸŽ¯ **Reasoning: The Soul** 
```
# AsyncWebCrawler Design Philosophy - Reasoning Context

## Why Async-First Architecture?

Crawl4AI uses AsyncWebCrawler as its primary interface because modern web 
scraping demands concurrency. Here's the thinking:

1. **Network I/O is slow**: Waiting synchronously wastes 90% of execution time
2. **Modern sites are complex**: Multiple resources load in parallel
3. **Scale matters**: You're rarely crawling just one page

## When to Use Session Management

Session management isn't just about performanceâ€”it's about appearing human:
- Use sessions when crawling multiple pages from the same domain
- Reuse browser contexts to maintain cookies and local storage
- But don't overdo it: too long sessions look suspicious

## The Cache Strategy Decision Tree
if static_content and infrequent_updates:
    use_cache_mode('read_write')
elif dynamic_content and real_time_needed:
    use_cache_mode('bypass')
else:
    use_cache_mode('read_only')  # Safe default
Copy
```

This is where the library creator's philosophy lives. It's not just *what* the library does, but *why* it does it that way. This is the hardest part to write because it requires genuine understandingâ€”and it's a red flag when a library lacks it. 
#### ðŸ’» **Examples: The Practice** 
```
# Crawling with JavaScript execution
result = await crawler.arun(
    url="https://example.com",
    js_code="window.scrollTo(0, document.body.scrollHeight);",
    wait_for="css:.lazy-loaded-content"
)

# Extracting structured data with CSS selectors
result = await crawler.arun(
    url="https://shop.example.com",
    extraction_strategy=CSSExtractionStrategy({
        "prices": "span.price::text",
        "titles": "h2.product-title::text"
    })
)

# Session-based crawling with custom headers
async with crawler:
    result1 = await crawler.arun(url1, session_id="product_scan")
    result2 = await crawler.arun(url2, session_id="product_scan")
Copy
```

Pure code. No fluff. Just patterns in action. Because sometimes, you just need to see how it's done. 
## Why This Matters (Especially for Smaller LLMs)
Here's the thing about AI assistants: the smaller ones can't think their way out of a paper bag. They're like eager internsâ€”full of potential but needing clear guidance. When you rely on a large language model to "figure it out" from raw API docs, you're asking it to reinvent your library's philosophy from scratch. Every. Single. Time.
By providing structured context across these three dimensions, we're not just documentingâ€”we're teaching. We're transferring not just knowledge, but wisdom.
## The Cultural DNA of Your Library
ðŸ§¬
**Your library's reasoning is its cultural DNA.**  
It reflects your taste, your architectural decisions, your opinions about how things should be done. A library without reasoning is like a recipe without techniquesâ€”sure, you have the ingredients, but good luck making something edible. 
Think about it: When you learn a new library, what are you really after? You want mastery. And mastery comes from understanding: - **Memory** tells you what's possible - **Reasoning** tells you what's sensible - **Examples** show you what's practical
Together, they create wisdom.
## Beyond Manual Documentation
Now, here's where it gets interesting. I didn't hand-craft thousands of lines of structured documentation for Crawl4AI. Who has that kind of time? Instead, I built a tool that:
  1. Analyzes your codebase
  2. Extracts API signatures and structures (Memory)
  3. Identifies patterns and architectural decisions (Reasoning)
  4. Collects real-world usage from tests and examples (Examples)
  5. Generates structured LLM context files


The beauty? This tool is becoming part of Crawl4AI itself. Because if we're going to revolutionize how AI understands our code, we might as well automate it.
## The Protocol, Not the Prescription
Remember: this is a protocol, not a prescription. Just as HTTP doesn't tell you what website to build, the LLM Context Protocol doesn't dictate your documentation style. It simply says:
> "If you want an AI to truly understand your library, it needs three things: facts, philosophy, and patterns."
How you deliver those is up to you. The protocol just ensures nothing important gets lost in translation.
## Try It Yourself
Curious about implementing this for your own library? The context generation tool will be open-sourced as part of Crawl4AI. If you're interested in early access or want to discuss the approach, drop me a DM on X [@unclecode](https://twitter.com/unclecode).
Because let's face it: if we're going to live in a world where AI writes half our code, we might as well teach it properly.
* * *
## A Final Thought
Memory + Reasoning + Examples = Wisdom 
And wisdom, not information, is what makes great developersâ€”human or artificial. 
* * *
_Want to see this in action? Check out the[Crawl4AI LLM Context Builder](https://docs.crawl4ai.com/core/llmtxt/) and experience the difference structured context makes._
#### On this page
  * [The Problem with Teaching Robots to Code](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-problem-with-teaching-robots-to-code)
  * [Enter the Three-Dimensional Context Protocol](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#enter-the-three-dimensional-context-protocol)
  * [The Three Pillars of Library Wisdom](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-three-pillars-of-library-wisdom)
  * [Why This Matters (Especially for Smaller LLMs)](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#why-this-matters-especially-for-smaller-llms)
  * [The Cultural DNA of Your Library](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-cultural-dna-of-your-library)
  * [Beyond Manual Documentation](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#beyond-manual-documentation)
  * [The Protocol, Not the Prescription](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#the-protocol-not-the-prescription)
  * [Try It Yourself](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#try-it-yourself)
  * [A Final Thought](https://docs.crawl4ai.com/blog/articles/llm-context-revolution/#a-final-thought)


* * *
> Feedback 
##### Search
xClose
Type to start searching
[ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/ "Ask Crawl4AI Assistant")
