<!-- Source: https://docs.crawl4ai.com/blog/releases/0.7.3/ -->

[Crawl4AI Documentation (v0.7.x)](https://docs.crawl4ai.com/)
  * [ Home ](https://docs.crawl4ai.com/)
  * [ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/)
  * [ Quick Start ](https://docs.crawl4ai.com/core/quickstart/)
  * [ Code Examples ](https://docs.crawl4ai.com/core/examples/)
  * [ Search ](https://docs.crawl4ai.com/blog/releases/0.7.3/)


[ unclecode/crawl4ai ](https://github.com/unclecode/crawl4ai)
Ã—
  * [Home](https://docs.crawl4ai.com/)
  * [Ask AI](https://docs.crawl4ai.com/core/ask-ai/)
  * [Quick Start](https://docs.crawl4ai.com/core/quickstart/)
  * [Code Examples](https://docs.crawl4ai.com/core/examples/)
  * Apps
    * [Demo Apps](https://docs.crawl4ai.com/apps/)
    * [C4A-Script Editor](https://docs.crawl4ai.com/apps/c4a-script/)
    * [LLM Context Builder](https://docs.crawl4ai.com/apps/llmtxt/)
  * Setup & Installation
    * [Installation](https://docs.crawl4ai.com/core/installation/)
    * [Docker Deployment](https://docs.crawl4ai.com/core/docker-deployment/)
  * Blog & Changelog
    * [Blog Home](https://docs.crawl4ai.com/blog/)
    * [Changelog](https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md)
  * Core
    * [Command Line Interface](https://docs.crawl4ai.com/core/cli/)
    * [Simple Crawling](https://docs.crawl4ai.com/core/simple-crawling/)
    * [Deep Crawling](https://docs.crawl4ai.com/core/deep-crawling/)
    * [Adaptive Crawling](https://docs.crawl4ai.com/core/adaptive-crawling/)
    * [URL Seeding](https://docs.crawl4ai.com/core/url-seeding/)
    * [C4A-Script](https://docs.crawl4ai.com/core/c4a-script/)
    * [Crawler Result](https://docs.crawl4ai.com/core/crawler-result/)
    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/core/browser-crawler-config/)
    * [Markdown Generation](https://docs.crawl4ai.com/core/markdown-generation/)
    * [Fit Markdown](https://docs.crawl4ai.com/core/fit-markdown/)
    * [Page Interaction](https://docs.crawl4ai.com/core/page-interaction/)
    * [Content Selection](https://docs.crawl4ai.com/core/content-selection/)
    * [Cache Modes](https://docs.crawl4ai.com/core/cache-modes/)
    * [Local Files & Raw HTML](https://docs.crawl4ai.com/core/local-files/)
    * [Link & Media](https://docs.crawl4ai.com/core/link-media/)
  * Advanced
    * [Overview](https://docs.crawl4ai.com/advanced/advanced-features/)
    * [Adaptive Strategies](https://docs.crawl4ai.com/advanced/adaptive-strategies/)
    * [Virtual Scroll](https://docs.crawl4ai.com/advanced/virtual-scroll/)
    * [File Downloading](https://docs.crawl4ai.com/advanced/file-downloading/)
    * [Lazy Loading](https://docs.crawl4ai.com/advanced/lazy-loading/)
    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/hooks-auth/)
    * [Proxy & Security](https://docs.crawl4ai.com/advanced/proxy-security/)
    * [Undetected Browser](https://docs.crawl4ai.com/advanced/undetected-browser/)
    * [Session Management](https://docs.crawl4ai.com/advanced/session-management/)
    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/multi-url-crawling/)
    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/crawl-dispatcher/)
    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/identity-based-crawling/)
    * [SSL Certificate](https://docs.crawl4ai.com/advanced/ssl-certificate/)
    * [Network & Console Capture](https://docs.crawl4ai.com/advanced/network-console-capture/)
    * [PDF Parsing](https://docs.crawl4ai.com/advanced/pdf-parsing/)
  * Extraction
    * [LLM-Free Strategies](https://docs.crawl4ai.com/extraction/no-llm-strategies/)
    * [LLM Strategies](https://docs.crawl4ai.com/extraction/llm-strategies/)
    * [Clustering Strategies](https://docs.crawl4ai.com/extraction/clustring-strategies/)
    * [Chunking](https://docs.crawl4ai.com/extraction/chunking/)
  * API Reference
    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/async-webcrawler/)
    * [arun()](https://docs.crawl4ai.com/api/arun/)
    * [arun_many()](https://docs.crawl4ai.com/api/arun_many/)
    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/api/parameters/)
    * [CrawlResult](https://docs.crawl4ai.com/api/crawl-result/)
    * [Strategies](https://docs.crawl4ai.com/api/strategies/)
    * [C4A-Script Reference](https://docs.crawl4ai.com/api/c4a-script-reference/)


* * *
  * [ðŸš€ Crawl4AI v0.7.3: The Multi-Config Intelligence Update](https://docs.crawl4ai.com/blog/releases/0.7.3/#crawl4ai-v073-the-multi-config-intelligence-update)
  * [ðŸŽ¯ What's New at a Glance](https://docs.crawl4ai.com/blog/releases/0.7.3/#whats-new-at-a-glance)
  * [ðŸŽ¨ Multi-URL Configurations: One Size Doesn't Fit All](https://docs.crawl4ai.com/blog/releases/0.7.3/#multi-url-configurations-one-size-doesnt-fit-all)
  * [ðŸ³ Docker: Flexible LLM Provider Configuration](https://docs.crawl4ai.com/blog/releases/0.7.3/#docker-flexible-llm-provider-configuration)
  * [ðŸ”§ Bug Fixes & Improvements](https://docs.crawl4ai.com/blog/releases/0.7.3/#bug-fixes-improvements)
  * [ðŸ“š Documentation Enhancements](https://docs.crawl4ai.com/blog/releases/0.7.3/#documentation-enhancements)
  * [ðŸ™ Acknowledgments](https://docs.crawl4ai.com/blog/releases/0.7.3/#acknowledgments)
  * [ðŸ“š Resources](https://docs.crawl4ai.com/blog/releases/0.7.3/#resources)


# ðŸš€ Crawl4AI v0.7.3: The Multi-Config Intelligence Update
_August 6, 2025 â€¢ 5 min read_
* * *
Today I'm releasing Crawl4AI v0.7.3â€”the Multi-Config Intelligence Update. This release brings smarter URL-specific configurations, flexible Docker deployments, important bug fixes, and documentation improvements that make Crawl4AI more robust and production-ready.
## ðŸŽ¯ What's New at a Glance
  * **Multi-URL Configurations** : Different crawling strategies for different URL patterns in a single batch
  * **Flexible Docker LLM Providers** : Configure LLM providers via environment variables
  * **Bug Fixes** : Resolved several critical issues for better stability
  * **Documentation Updates** : Clearer examples and improved API documentation


## ðŸŽ¨ Multi-URL Configurations: One Size Doesn't Fit All
**The Problem:** You're crawling a mix of documentation sites, blogs, and API endpoints. Each needs different handlingâ€”caching for docs, fresh content for news, structured extraction for APIs. Previously, you'd run separate crawls or write complex conditional logic.
**My Solution:** I implemented URL-specific configurations that let you define different strategies for different URL patterns in a single crawl batch. First match wins, with optional fallback support.
### Technical Implementation
```
from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, MatchMode

# Define specialized configs for different content types
configs = [
    # Documentation sites - aggressive caching, include links
    CrawlerRunConfig(
        url_matcher=["*docs*", "*documentation*"],
        cache_mode="write",
        markdown_generator_options={"include_links": True}
    ),

    # News/blog sites - fresh content, scroll for lazy loading
    CrawlerRunConfig(
        url_matcher=lambda url: 'blog' in url or 'news' in url,
        cache_mode="bypass",
        js_code="window.scrollTo(0, document.body.scrollHeight/2);"
    ),

    # API endpoints - structured extraction
    CrawlerRunConfig(
        url_matcher=["*.json", "*api*"],
        extraction_strategy=LLMExtractionStrategy(
            provider="openai/gpt-4o-mini",
            extraction_type="structured"
        )
    ),

    # Default fallback for everything else
    CrawlerRunConfig()  # No url_matcher = matches everything
]

# Crawl multiple URLs with appropriate configs
async with AsyncWebCrawler() as crawler:
    results = await crawler.arun_many(
        urls=[
            "https://docs.python.org/3/",      # â†’ Uses documentation config
            "https://blog.python.org/",        # â†’ Uses blog config  
            "https://api.github.com/users",    # â†’ Uses API config
            "https://example.com/"             # â†’ Uses default config
        ],
        config=configs
    )
Copy
```

**Matching Capabilities:** - **String Patterns** : Wildcards like `"*.pdf"`, `"*/blog/*"` - **Function Matchers** : Lambda functions for complex logic - **Mixed Matchers** : Combine strings and functions with AND/OR logic - **Fallback Support** : Default config when nothing matches
**Expected Real-World Impact:** - **Mixed Content Sites** : Handle blogs, docs, and downloads in one crawl - **Multi-Domain Crawling** : Different strategies per domain without separate runs - **Reduced Complexity** : No more if/else forests in your extraction code - **Better Performance** : Each URL gets exactly the processing it needs
## ðŸ³ Docker: Flexible LLM Provider Configuration
**The Problem:** Hardcoded LLM providers in Docker deployments. Want to switch from OpenAI to Groq? Rebuild and redeploy. Testing different models? Multiple Docker images.
**My Solution:** Configure LLM providers via environment variables. Switch providers without touching code or rebuilding images.
### Deployment Flexibility
```
# Option 1: Direct environment variables
docker run -d \
  -e LLM_PROVIDER="groq/llama-3.2-3b-preview" \
  -e GROQ_API_KEY="your-key" \
  -p 11235:11235 \
  unclecode/crawl4ai:latest

# Option 2: Using .llm.env file (recommended for production)
# Create .llm.env file:
# LLM_PROVIDER=openai/gpt-4o-mini
# OPENAI_API_KEY=your-openai-key
# GROQ_API_KEY=your-groq-key

docker run -d \
  --env-file .llm.env \
  -p 11235:11235 \
  unclecode/crawl4ai:latest
Copy
```

Override per request when needed: 
```
# Use default provider from .llm.env
response = requests.post("http://localhost:11235/crawl", json={
    "url": "https://example.com",
    "extraction_strategy": {"type": "llm"}
})

# Override to use different provider for this specific request
response = requests.post("http://localhost:11235/crawl", json={
    "url": "https://complex-page.com",
    "extraction_strategy": {
        "type": "llm",
        "provider": "openai/gpt-4"  # Override default
    }
})
Copy
```

**Expected Real-World Impact:** - **Cost Optimization** : Use cheaper models for simple tasks, premium for complex - **A/B Testing** : Compare provider performance without deployment changes - **Fallback Strategies** : Switch providers on-the-fly during outages - **Development Flexibility** : Test locally with one provider, deploy with another - **Secure Configuration** : Keep API keys in `.llm.env` file, not in commands
## ðŸ”§ Bug Fixes & Improvements
This release includes several important bug fixes that improve stability and reliability:
  * **URL Matcher Fallback** : Fixed edge cases in URL pattern matching logic
  * **Memory Management** : Resolved memory leaks in long-running crawl sessions
  * **Sitemap Processing** : Fixed redirect handling in sitemap fetching
  * **Table Extraction** : Improved table detection and extraction accuracy
  * **Error Handling** : Better error messages and recovery from network failures


## ðŸ“š Documentation Enhancements
Based on community feedback, we've updated: - Clearer examples for multi-URL configuration - Improved CrawlResult documentation with all available fields - Fixed typos and inconsistencies across documentation - Added real-world URLs in examples for better understanding - New comprehensive demo showcasing all v0.7.3 features
## ðŸ™ Acknowledgments
Thanks to our contributors and the entire community for feedback and bug reports.
## ðŸ“š Resources
  * [Full Documentation](https://docs.crawl4ai.com)
  * [GitHub Repository](https://github.com/unclecode/crawl4ai)
  * [Discord Community](https://discord.gg/crawl4ai)
  * [Feature Demo](https://github.com/unclecode/crawl4ai/blob/main/docs/releases_review/demo_v0.7.3.py)


* * *
_Crawl4AI continues to evolve with your needs. This release makes it smarter, more flexible, and more stable. Try the new multi-config feature and flexible Docker deploymentâ€”they're game changers!_
**Happy Crawling! ðŸ•·ï¸**
_- The Crawl4AI Team_
#### On this page
  * [ðŸŽ¯ What's New at a Glance](https://docs.crawl4ai.com/blog/releases/0.7.3/#whats-new-at-a-glance)
  * [ðŸŽ¨ Multi-URL Configurations: One Size Doesn't Fit All](https://docs.crawl4ai.com/blog/releases/0.7.3/#multi-url-configurations-one-size-doesnt-fit-all)
  * [Technical Implementation](https://docs.crawl4ai.com/blog/releases/0.7.3/#technical-implementation)
  * [ðŸ³ Docker: Flexible LLM Provider Configuration](https://docs.crawl4ai.com/blog/releases/0.7.3/#docker-flexible-llm-provider-configuration)
  * [Deployment Flexibility](https://docs.crawl4ai.com/blog/releases/0.7.3/#deployment-flexibility)
  * [ðŸ”§ Bug Fixes & Improvements](https://docs.crawl4ai.com/blog/releases/0.7.3/#bug-fixes-improvements)
  * [ðŸ“š Documentation Enhancements](https://docs.crawl4ai.com/blog/releases/0.7.3/#documentation-enhancements)
  * [ðŸ™ Acknowledgments](https://docs.crawl4ai.com/blog/releases/0.7.3/#acknowledgments)
  * [ðŸ“š Resources](https://docs.crawl4ai.com/blog/releases/0.7.3/#resources)


* * *
> Feedback 
##### Search
xClose
Type to start searching
[ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/ "Ask Crawl4AI Assistant")
